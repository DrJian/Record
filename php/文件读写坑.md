## 文件读写
这段时间在做PHP相关的开发，经常会做PHP下的文件读写，主要用于跑数据需求。

大家平常在工作的过程中，经常会涉及到一些数据需求，这些数据常常无法通过一条sql语句完成，或者sql的查询效率会很低；相反地，我们可以将数据以高效率的方式跑到本地。例如，通过linux下的管道命令。之后，我们使用任意语言在本地做一个数据解析，可以更快地完成任务。

###文件读写过程中，经常会踩的一些坑
####1. 读数据时，不删除换行"\n"，这个问题看起来简单，确经常会让我们犯错，例如，现在有500W量级文章，我想了解其中包含109种tag的文章浏览量，那么对于这个问题，我们应该如何做，来看看PHP代码是如何实现的。

	<?php
	ini_set('memory_limit', '2048M');
	$keyFile = fopen('./key.txt', 'r');
	$arrKeyWords = array();
	
	$strKey = '';
	while($strKey = trim(fgets($keyFile))){///这里我们使用了trim函数，来避免将\n读进键值数组的Key中，这会导致在下面使用Hash时，对应key匹配无法成功
	    $arrKeyWords[$strKey] = 0;
	}
	//var_dump($arrKeyWords);die();
	$objTaskFile = fopen('./allData', 'r');
	$strRow = '';
	while($strRow = fgets($objTaskFile)){
	    $arrInfo = explode("\t", $strRow);
	    //获取pv
	    $intPV = intval($arrInfo[2]);
	    //获取tag字符串，并用urldecode解码
	    $strTags = $arrInfo[1];
	    $strDecodedTags = urldecode($strTags);
	    //将tag解析为数组
	    $arrTags = explode(",", $strDecodedTags);
	    
	    if(empty($arrTags)){
	        continue;
	    }
	    foreach($arrTags as $tag){
	        if(!isset($arrKeyWords[$tag])){
	            continue;
	        }
	        $arrKeyWords[$tag] += $intPV;
	    }
	    unset($intPV);
	    unset($strTags);
	    unset($arrInfo);
	}
	$strFile = fopen('./result', 'w');
	foreach($arrKeyWords as $key => $word){
	    fputs($strFile , $key . "\t" . $word . "\n");
	}

####2. 不同的跑数据方法各有快慢，那么对于在数组中做查找时，最快的方法无疑是Hash了，对于PHP即键值数组，注意上面代码中的isset()方法。对应于Java，那就是大名鼎鼎的HashMap这个集合类了，相比较传统的查找方法，速度上可以提升非常多，之前做过测试数据，有兴趣地同学可以尝试一下。

####3. 巧用分割函数，对应PHP代码中的explode和implode，可以高效的解决分隔符统一的文本问题。

**上面那段文本解析地是诸如此类的数据,key.txt中存储的是要查找的关键词**

	2583404 %E5%81%A5%E8%BA%AB%2C%E5%BF%A0%E5%91%8A 27
	2289115 %E6%88%B7%E5%8F%A3%2C%E8%BF%81%E5%85%A5 57
	2551112 spss    75
	2547769 %E5%B1%85%E4%B8%AD%2C%E5%8F%B3%E5%AF%B9%E9%BD%90    1005